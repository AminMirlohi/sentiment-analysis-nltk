from nltk import sent_tokenize, pos_tag
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet as wn
from nltk.corpus import sentiwordnet as swn
from nltk.sentiment.util import mark_negation
from nltk.corpus import opinion_lexicon
from nltk.tokenize import word_tokenize, sent_tokenize
import nltk
print(1)
# nltk.download('punkt')
# nltk.download('averaged_perceptron_tagger')
# nltk.download('wordnet')
# nltk.download('sentiwordnet')
# nltk.download("opinion_lexicon")
from string import punctuation
from IPython.display import display
import pandas as pd
import numpy as np
print(1)
import seaborn as sns
print(1)
import matplotlib.pyplot as plt
import ndjson
print(1)
import pandas as pd
import numpy as np
print(1)
import seaborn as sns
from sklearn.metrics import confusion_matrix
print(1)


pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)
print(1)

def convertToWordnet(tag):
    if tag.startswith('J'):
        return wn.ADJ
    elif tag.startswith('N'):
        return wn.NOUN
    elif tag.startswith('R'):
        return wn.ADV
    elif tag.startswith('V'):
        return wn.VERB
    return None
    
def getSentimentScore(text):

    total_score = 0
    raw_sentences = sent_tokenize(text)
    
    for sentence in raw_sentences:

        sent_score = 0     
        sentence = str(sentence)
        #print(sentence)
        sentence = sentence.replace("<br />"," ").translate(str.maketrans('','',punctuation)).lower()
        tokens = TreebankWordTokenizer().tokenize(text)
        tags = pos_tag(tokens)
        for word, tag in tags:
            wn_tag = convertToWordnet(tag)
            if not wn_tag:
                continue
            lemma = WordNetLemmatizer().lemmatize(word, pos=wn_tag)
            if not lemma:
                continue
            synsets = wn.synsets(lemma, pos=wn_tag)
            if not synsets:
                continue
            synset = synsets[0]
            swn_synset = swn.senti_synset(synset.name())
            sent_score += swn_synset.pos_score() - swn_synset.neg_score()

        total_score = total_score + (sent_score / len(tokens))

    
    return (total_score / len(raw_sentences)) * 100

def getSentimentScoreOplex(text):
    
    """
        This method returns the sentiment score of a given text using nltk opinion lexicon.
        input: text
        output: numeric (double) score, >0 means positive sentiment and <0 means negative sentiment.
    """    
    total_score = 0

    raw_sentences = sent_tokenize(text)
    
    for sentence in raw_sentences:

        sent_score = 0     
        sentence = str(sentence)
        sentence = sentence.replace("<br />"," ").translate(str.maketrans('','',punctuation)).lower()
        tokens = TreebankWordTokenizer().tokenize(text)
        for token in tokens:
            sent_score = sent_score + 1 if token in pos_words else (sent_score - 1 if token in neg_words else sent_score)
        total_score = total_score + (sent_score / len(tokens))

    
    return total_score
print(1)
# reading reviews from json file
with open('data/amazon_ratings/Movies_and_TV.json') as f:
    data = ndjson.load(f)

print(1)
reviews_df = pd.DataFrame(data)
print(1)
reviews = reviews_df.sample(n=50000, random_state=42)
print(1)

reviews.dropna(subset=['reviewText'], inplace=True)
reviews['swn_score'] = reviews['reviewText'].apply(lambda text : getSentimentScore(text))
print(1)
reviews['swn_sentiment'] = reviews['swn_score'].apply(lambda x: "positive" if x>1 else ("negative" if x<0.5 else "neutral"))
print(1)
reviews['true_sentiment'] = reviews['overall'].apply(lambda x: "positive" if x>=4 else ("neutral" if x==3 else "negative"))
print(1)
y_swn_pred, y_true = reviews['swn_sentiment'].tolist(), reviews['true_sentiment'].tolist()
print(1)
pos_words = list(opinion_lexicon.positive())
neg_words = list(opinion_lexicon.negative())
print(1)
reviews['oplex_sentiment_score'] = reviews['reviewText'].apply(lambda x: getSentimentScoreOplex(x))
print(1)
reviews['oplex_sentiment'] = \
    reviews['oplex_sentiment_score'].apply(lambda x: "positive" if x>0.1 else ("negative" if x<0 else "neutral"))
print(1)
reviews['oplex_sentiment'].value_counts(dropna=False)
print(1)
y_oplex_pred = reviews['oplex_sentiment'].tolist()
oplex_cm = confusion_matrix(y_true, y_oplex_pred)
print(1)
fig , ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))
sns.heatmap(oplex_cm, cmap='viridis_r', annot=True, fmt='d', square=True, ax=ax)
ax.set_xlabel('Predicted')
ax.set_ylabel('True');
